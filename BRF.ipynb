{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts:\n",
      "Label\n",
      "0    204368\n",
      "1     34767\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 239135 entries, 0 to 239134\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   row     239135 non-null  int64  \n",
      " 1   col     239135 non-null  int64  \n",
      " 2   year    239135 non-null  int64  \n",
      " 3   month   239135 non-null  int64  \n",
      " 4   day     239135 non-null  int64  \n",
      " 5   hour    239135 non-null  int64  \n",
      " 6   B04B    239135 non-null  float64\n",
      " 7   B05B    239135 non-null  float64\n",
      " 8   B06B    239135 non-null  float64\n",
      " 9   B09B    239135 non-null  float64\n",
      " 10  B10B    239135 non-null  float64\n",
      " 11  B11B    239135 non-null  float64\n",
      " 12  B12B    239135 non-null  float64\n",
      " 13  B14B    239135 non-null  float64\n",
      " 14  B16B    239135 non-null  float64\n",
      " 15  I2B     239135 non-null  float64\n",
      " 16  I4B     239135 non-null  float64\n",
      " 17  IRB     239135 non-null  float64\n",
      " 18  VSB     239135 non-null  float64\n",
      " 19  WVB     239135 non-null  float64\n",
      " 20  Label   239135 non-null  int64  \n",
      "dtypes: float64(14), int64(7)\n",
      "memory usage: 38.3 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'D:\\\\1 code AI'\n",
    "file_names = ['new_data_v1.csv']\n",
    "datasets = [pd.read_csv(os.path.join(file_path, file)) for file in file_names]\n",
    "dataset = pd.concat(datasets, ignore_index=True)\n",
    "\n",
    "# Count the number of labels 0 and 1\n",
    "label_counts = dataset['Label'].value_counts()\n",
    "print(\"Label counts:\")\n",
    "print(label_counts)\n",
    "\n",
    "dataset.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       B04B      B05B      B06B       B09B       B10B       B11B       B12B  \\\n",
      "0  0.084788  0.053601  0.030115  253.87752  261.63812  281.48710  260.33334   \n",
      "1  0.129801  0.103687  0.064551  253.48486  261.10180  279.65836  259.01260   \n",
      "2  0.088053  0.074731  0.043408  253.62572  261.10180  281.48782  260.33664   \n",
      "3  0.085429  0.070825  0.040283  253.06673  261.10593  280.73180  259.73105   \n",
      "4  0.099121  0.091174  0.057520  252.52501  260.70062  280.29822  259.61038   \n",
      "\n",
      "        B14B       B16B        I2B        I4B        IRB       VSB        WVB  \n",
      "0  285.00070  269.99298  281.76694  286.36456  285.24005  0.070424  244.27534  \n",
      "1  282.17892  268.44498  279.95640  286.18780  282.48993  0.099792  244.05240  \n",
      "2  284.34457  269.33520  281.68080  286.60724  284.50903  0.070424  243.55762  \n",
      "3  283.88354  269.33356  280.94617  285.77060  284.15130  0.074331  243.33647  \n",
      "4  283.85870  268.99704  280.34543  287.78340  284.39117  0.082174  242.84953  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 239135 entries, 0 to 239134\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   B04B    239135 non-null  float64\n",
      " 1   B05B    239135 non-null  float64\n",
      " 2   B06B    239135 non-null  float64\n",
      " 3   B09B    239135 non-null  float64\n",
      " 4   B10B    239135 non-null  float64\n",
      " 5   B11B    239135 non-null  float64\n",
      " 6   B12B    239135 non-null  float64\n",
      " 7   B14B    239135 non-null  float64\n",
      " 8   B16B    239135 non-null  float64\n",
      " 9   I2B     239135 non-null  float64\n",
      " 10  I4B     239135 non-null  float64\n",
      " 11  IRB     239135 non-null  float64\n",
      " 12  VSB     239135 non-null  float64\n",
      " 13  WVB     239135 non-null  float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 25.5 MB\n",
      "None\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: Label, dtype: int64\n",
      "Label\n",
      "0    204368\n",
      "1     34767\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check if columns exist before dropping\n",
    "columns_drop = [\"Label\", \"row\", \"col\", \"year\", \"month\", \"day\", \"hour\"]\n",
    "existing_columns_to_drop = [col for col in columns_drop if col in dataset.columns]\n",
    "\n",
    "X = dataset.drop(columns=existing_columns_to_drop)\n",
    "y = dataset[\"Label\"]\n",
    "\n",
    "print(X.head())\n",
    "print(X.info())\n",
    "print(y.head())\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 167394\n",
      "Test set size: 71741\n",
      "Training set label distribution:\n",
      "Label\n",
      "0    143026\n",
      "1     24368\n",
      "Name: count, dtype: int64\n",
      "Test set label distribution:\n",
      "Label\n",
      "0    61342\n",
      "1    10399\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train (80%) and test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "print(\"Training set label distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"Test set label distribution:\")\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chạy bừa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Define the model\n",
    "BRFmodel =  (n_estimators=536, max_depth=50, min_samples_split=4, min_samples_leaf=4, max_features='log2', class_weight='balanced', random_state=42)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "\n",
    "# Train the model and evaluate using cross-validation\n",
    "scores = cross_validate(BRFmodel, X_train, y_train, scoring=['accuracy', 'precision', 'recall', 'f1'], cv=cv, n_jobs=-1)\n",
    "\n",
    "# Print the scores\n",
    "print(\"Accuracy: \", scores['test_accuracy'].mean())\n",
    "print(\"Precision: \", scores['test_precision'].mean())\n",
    "print(\"Recall: \", scores['test_recall'].mean())\n",
    "print(\"F1 Score: \", scores['test_f1'].mean())\n",
    "\n",
    "\n",
    "# Fit the model on the training data\n",
    "BRFmodel.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = BRFmodel.predict(X_test)\n",
    "\n",
    "# Generate and print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['No Rain', 'Rain'], yticklabels=['No Rain', 'Rain'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 10 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Enviroment\\Anaconda\\envs\\AI\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "d:\\Enviroment\\Anaconda\\envs\\AI\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "d:\\Enviroment\\Anaconda\\envs\\AI\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 500, 'min_samples_split': 14, 'min_samples_leaf': 16, 'max_features': None, 'max_depth': 50, 'class_weight': 'balanced_subsample'}\n",
      "Best F1 Score: 0.607914312243648\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.83      0.90     40859\n",
      "           1       0.47      0.85      0.60      6968\n",
      "\n",
      "    accuracy                           0.84     47827\n",
      "   macro avg       0.72      0.84      0.75     47827\n",
      "weighted avg       0.90      0.84      0.85     47827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': range(100, 501, 100),  # You can adjust the range if needed\n",
    "    'max_depth': range(10, 51, 10),\n",
    "    'min_samples_split': range(2, 20, 2),\n",
    "    'min_samples_leaf': range(2, 20, 2),\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "BRFmodel = BalancedRandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "\n",
    "# Initialize the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=BRFmodel, \n",
    "    param_distributions=param_grid, \n",
    "    n_iter=10, \n",
    "    scoring='f1', \n",
    "    cv=cv, \n",
    "    random_state=42, \n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best F1 Score:\", random_search.best_score_)\n",
    "\n",
    "# Predict on the test data using the best model\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Generate and print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Enviroment\\Anaconda\\envs\\AI\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "d:\\Enviroment\\Anaconda\\envs\\AI\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "d:\\Enviroment\\Anaconda\\envs\\AI\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Generate the classification report\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m(y_test, y_pred)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, report)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "# Initialize the classifier with the best parameters\n",
    "clf = BalancedRandomForestClassifier(\n",
    "    n_estimators=650,\n",
    "    min_samples_split=14,\n",
    "    min_samples_leaf=16,\n",
    "    max_features=None,\n",
    "    max_depth=50,\n",
    "    class_weight='balanced_subsample'\n",
    ")\n",
    "\n",
    "# Fit the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90     61342\n",
      "           1       0.47      0.85      0.60     10399\n",
      "\n",
      "    accuracy                           0.84     71741\n",
      "   macro avg       0.72      0.84      0.75     71741\n",
      "weighted avg       0.90      0.84      0.85     71741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
